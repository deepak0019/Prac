{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrD87ZBHhsAv",
        "outputId": "2ca9f014-e962-483b-d80c-a31257c46b8f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 16 03:59:05 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp9JZcQUh3Kl",
        "outputId": "4cee994d-a99f-4e9d-f8c9-793ad3d71920"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-rg1frv58\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-rg1frv58\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 326b0a57a80c6d0b4bad25ca7adf8138419ef1cb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xosAmJ-IgKEb",
        "outputId": "9ccc2355-24ea-4ee4-8a2a-92c7b49eb520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd37KlJugV4Z",
        "outputId": "98a26548-203c-4cd2-9b4f-26f961603761"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void matrixMultiply(int *a, int *b, int *c, int width) {\n",
        "\n",
        " int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        " int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\n",
        "\n",
        "if (row < width && col < width) {\n",
        "\n",
        " int sum = 0;\n",
        "\n",
        " for (int k = 0; k < width; ++k) {\n",
        "\n",
        " sum += a[row * width + k] * b[k * width + col];\n",
        "\n",
        " }\n",
        "\n",
        " c[row * width + col] = sum;\n",
        "\n",
        " }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "void displayMatrix(int *matrix, int width) {\n",
        "\n",
        " for (int i = 0; i < width; ++i) {\n",
        "\n",
        " for (int j = 0; j < width; ++j) {\n",
        "\n",
        " printf(\"%d\\t\", matrix[i * width + j]);\n",
        "\n",
        " }\n",
        "\n",
        " printf(\"\\n\");\n",
        "\n",
        " }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "\n",
        " const int width = 3;\n",
        "\n",
        " const int size = width * width * sizeof(int);\n",
        "\n",
        "\n",
        "\n",
        "#  // Host matrices\n",
        "\n",
        " int h_mat1[width][width] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n",
        "\n",
        " int h_mat2[width][width] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n",
        "\n",
        " int h_result[width][width];\n",
        "\n",
        "\n",
        "\n",
        " // Device matrices\n",
        "\n",
        " int *d_mat1, *d_mat2, *d_result;\n",
        "\n",
        " cudaMalloc((void **)&d_mat1, size);\n",
        "\n",
        " cudaMalloc((void **)&d_mat2, size);\n",
        " cudaMalloc((void **)&d_result, size);\n",
        "\n",
        "\n",
        "\n",
        " // Copy matrices from host to device\n",
        "\n",
        " cudaMemcpy(d_mat1, h_mat1, size, cudaMemcpyHostToDevice);\n",
        "\n",
        " cudaMemcpy(d_mat2, h_mat2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "\n",
        " // Define grid and block dimensions\n",
        "\n",
        " dim3 threadsPerBlock(16, 16);\n",
        "\n",
        " dim3 blocksPerGrid((width + 15) / 16, (width + 15) / 16);\n",
        "\n",
        "\n",
        "\n",
        " // Launch kernel\n",
        "\n",
        " matrixMultiply<<<blocksPerGrid, threadsPerBlock>>>(d_mat1, d_mat2, d_result, width);\n",
        "\n",
        "\n",
        "\n",
        " // Copy result back to host\n",
        "\n",
        " cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\n",
        " // Display the result\n",
        "\n",
        " printf(\"Result of matrix multiplication:\\n\");\n",
        "\n",
        " displayMatrix((int *)h_result, width);\n",
        "\n",
        "\n",
        "\n",
        " // Free device memory\n",
        "\n",
        " cudaFree(d_mat1);\n",
        "\n",
        " cudaFree(d_mat2);\n",
        "\n",
        " cudaFree(d_result);\n",
        "\n",
        "\n",
        "\n",
        " return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1Ru5DOjgaxt",
        "outputId": "febad4da-85dc-442d-d326-0dfc39f6bef5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of matrix multiplication:\n",
            "0\t0\t0\t\n",
            "0\t0\t0\t\n",
            "0\t0\t0\t\n",
            "\n"
          ]
        }
      ]
    }
  ]
}