{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U2rOIJajh4Y",
        "outputId": "58d8d156-e88d-4f6b-f6e2-e5bb2ac53f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHMsH-D4jsGG",
        "outputId": "0693f92e-9e3a-49b7-cb4c-df5565ada995"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpitq5ogn2\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "\n",
        "// CUDA kernel for matrix multiplication\n",
        "__global__ void matrixMultiply(int *a, int *b, int *c, int width) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\n",
        "    if (row < width && col < width) {\n",
        "        int sum = 0;\n",
        "        for (int k = 0; k < width; ++k) {\n",
        "            sum += a[row * width + k] * b[k * width + col];\n",
        "        }\n",
        "        c[row * width + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// Function to display a matrix\n",
        "void displayMatrix(int *matrix, int width) {\n",
        "    for (int i = 0; i < width; ++i) {\n",
        "        for (int j = 0; j < width; ++j) {\n",
        "            printf(\"%d\\t\", matrix[i * width + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "    const int width = 3;\n",
        "    const int size = width * width * sizeof(int);\n",
        "\n",
        "\n",
        "    // Host matrices\n",
        "    int h_mat1[width][width] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n",
        "    int h_mat2[width][width] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n",
        "    int h_result[width][width];\n",
        "\n",
        "\n",
        "    // Device matrices\n",
        "    int *d_mat1, *d_mat2, *d_result;\n",
        "    cudaMalloc((void **)&d_mat1, size);\n",
        "    cudaMalloc((void **)&d_mat2, size);\n",
        "    cudaMalloc((void **)&d_result, size);\n",
        "\n",
        "\n",
        "    // Copy matrices from host to device\n",
        "    cudaMemcpy(d_mat1, h_mat1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_mat2, h_mat2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 blocksPerGrid((width + 15) / 16, (width + 15) / 16);\n",
        "\n",
        "\n",
        "    // Launch kernel\n",
        "    matrixMultiply<<<blocksPerGrid, threadsPerBlock>>>(d_mat1, d_mat2, d_result, width);\n",
        "\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    // Display the result\n",
        "    printf(\"Result of matrix multiplication:\\n\");\n",
        "    displayMatrix((int *)h_result, width);\n",
        "\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_mat1);\n",
        "    cudaFree(d_mat2);\n",
        "    cudaFree(d_result);\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atvPrfXnjvQQ",
        "outputId": "26e2fe8b-78b9-4afd-ec4e-088b6538f658"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of matrix multiplication:\n",
            "30\t24\t18\t\n",
            "84\t69\t54\t\n",
            "138\t114\t90\t\n",
            "\n"
          ]
        }
      ]
    }
  ]
}